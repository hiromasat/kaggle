{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Starter notebook ”Dogs vs. Cats” with EfficientNet vs My own model\nThis notebook shows a flow of \"Dogs and Cats\" distinguish model development.  \nhttps://www.kaggle.com/c/dogs-vs-cats/  \n\n[Agenda]\n1. Import libraries  \n2.　Data preparation  \n    2-1. Unzip data  \n    2-2. Path and file name setting  \n    2-3. making directory tree for ImageDataGenerator  \n    2-4. Copy picture data to tree for ImageDataGenerator  \n3. Training  \n    3-1. setting for training  \n    3-2. dataset confirmation  \n    3-3. ImageDataGenerator  \n    3-4. Network definition  \n    3-5. train  \n4. Save Model  \n5. Model evaluation  \n    5-1. Confusion matrix  \n6. Prediction with Test data  \n7. Create submission file  ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-28T00:51:08.289942Z","iopub.execute_input":"2021-05-28T00:51:08.290332Z","iopub.status.idle":"2021-05-28T00:51:08.300566Z","shell.execute_reply.started":"2021-05-28T00:51:08.290301Z","shell.execute_reply":"2021-05-28T00:51:08.29944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-05-28T07:12:27.418279Z","iopub.execute_input":"2021-05-28T07:12:27.418596Z","iopub.status.idle":"2021-05-28T07:12:28.085073Z","shell.execute_reply.started":"2021-05-28T07:12:27.418566Z","shell.execute_reply":"2021-05-28T07:12:28.084149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Import libraries","metadata":{}},{"cell_type":"code","source":"# File I/O\nimport csv\nimport subprocess\nimport shutil\nimport os\nfrom glob import glob\nfrom datetime import datetime\nfrom PIL import Image\n\n# Data processing\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n\n# Image processing\nimport cv2\nfrom scipy.ndimage import rotate\nimport scipy.misc\n\n# Graph\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras import Model\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten, Dropout\nfrom keras.layers.core import Dense\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import np_utils\nfrom keras.optimizers import Adam\nfrom keras.optimizers import Adagrad\nfrom keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n# EfficientNet\nfrom tensorflow.keras.applications import EfficientNetB0\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom IPython.display import display\nimport ipywidgets as widgets","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:17:38.265511Z","iopub.execute_input":"2021-05-28T04:17:38.265848Z","iopub.status.idle":"2021-05-28T04:17:38.289194Z","shell.execute_reply.started":"2021-05-28T04:17:38.265818Z","shell.execute_reply":"2021-05-28T04:17:38.287569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Data preparation  \n## 2-1. Unzip data  \nI will use ImageGenerator to load data for training.  \nTest data poctures shall not be stored in Test data path folder directory.Test data path shall have one folder.  \nIf prediction target pictures are stored in the test data path folder directory, error occurrs.   ","metadata":{}},{"cell_type":"code","source":"!unzip -q '../input/dogs-vs-cats/train.zip' -d '/kaggle/working/' # ->'/kaggle/working/train'\n!unzip -q '../input/dogs-vs-cats/test1.zip' -d '/kaggle/working/test/' # ->'/kaggle/working/test/test1'","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:26:20.533346Z","iopub.execute_input":"2021-05-28T04:26:20.533711Z","iopub.status.idle":"2021-05-28T04:26:26.615442Z","shell.execute_reply.started":"2021-05-28T04:26:20.533679Z","shell.execute_reply":"2021-05-28T04:26:26.614302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.move('/kaggle/working/train/', '/kaggle/working/train_raw/all_pics')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:26:31.656938Z","iopub.execute_input":"2021-05-28T04:26:31.65728Z","iopub.status.idle":"2021-05-28T04:26:31.665862Z","shell.execute_reply.started":"2021-05-28T04:26:31.657249Z","shell.execute_reply":"2021-05-28T04:26:31.664902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. Path and file name setting  \nAgain, test path folder shall have one more folder at least.  ","metadata":{}},{"cell_type":"code","source":"root_path = '/kaggle/working'\n\n# Path of Unzipping data stored (root)\ntrain_raw_root_path = '/kaggle/working/train_raw/'\n\n\n# Path of Unzipping data stored \ntrain_raw_path = '/kaggle/working/train_raw/all_pics'\n\n# Path for training\ntrain_root_path = '/kaggle/working/train_root'\ntest_path = '/kaggle/working/test'\nsubmit_file = 'submission.csv'\n\n# Path for Imagegenerator\ntrain_dir = os.path.join(train_root_path, 'train')\nvalid_dir = os.path.join(train_root_path, 'valid')\n\nprint(train_dir)\nprint(valid_dir)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:14:35.454848Z","iopub.execute_input":"2021-05-28T02:14:35.455223Z","iopub.status.idle":"2021-05-28T02:14:35.460748Z","shell.execute_reply.started":"2021-05-28T02:14:35.455194Z","shell.execute_reply":"2021-05-28T02:14:35.459965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-3. making directory tree for ImageDataGenerator","metadata":{}},{"cell_type":"markdown","source":"Making each file name list of classificaion target categories","metadata":{}},{"cell_type":"markdown","source":"## 2-4. Copy picture data to tree for ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"# picture file name list\ndata_img_list = [os.path.basename(f) for f in glob(f'{train_raw_path}/*.jpg')]\ntest_img_list = [os.path.basename(f) for f in glob(f'{test_path}/test1/*.jpg')]","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:53:31.561229Z","iopub.execute_input":"2021-05-28T00:53:31.561575Z","iopub.status.idle":"2021-05-28T00:53:31.719305Z","shell.execute_reply.started":"2021-05-28T00:53:31.561545Z","shell.execute_reply":"2021-05-28T00:53:31.718446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target labels list\ntarget_labels = ['cat', 'dog']\n\n# directories in the train_root path\ndirs = ['train', 'valid']#\n\n# make dirctories for data store\nfor d in dirs:\n    for label in target_labels:\n        os.makedirs(os.path.join(train_root_path, d, label), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:53:27.144825Z","iopub.execute_input":"2021-05-28T00:53:27.145227Z","iopub.status.idle":"2021-05-28T00:53:27.150428Z","shell.execute_reply.started":"2021-05-28T00:53:27.145192Z","shell.execute_reply":"2021-05-28T00:53:27.149457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initializing instance\nimg_cat_list = []\nimg_dog_list = []\n\n# make dog and cat file name list\nfor f in data_img_list:\n    label = f.split('.')[0]\n    if label == target_labels[0]:\n        img_cat_list.append(f)\n    elif label == target_labels[1]:\n        img_dog_list.append(f)\n    else:\n        print('abnormal file name is found', f)\n\n# Split data to for train and for valid\ntrain_list_cat, val_list_cat, train_list_dog, val_list_dog = train_test_split(img_cat_list, img_dog_list, \n                                                                  test_size=0.3,\n                                                                 random_state=46)\n# directories list to join to train_root path\ncopy_to_dirs = ['train/cat', 'valid/cat', 'train/dog', 'valid/dog']\nimg_lists = [train_list_cat, val_list_cat, train_list_dog, val_list_dog] \n\n# Copy to each directories\nfor to_dir in copy_to_dirs:\n    for f in img_lists[copy_to_dirs.index(to_dir)]:\n        shutil.copyfile(os.path.join(train_raw_path,f), os.path.join(train_root_path, to_dir,f))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:53:35.36757Z","iopub.execute_input":"2021-05-28T00:53:35.367904Z","iopub.status.idle":"2021-05-28T00:53:37.807224Z","shell.execute_reply.started":"2021-05-28T00:53:35.367874Z","shell.execute_reply":"2021-05-28T00:53:37.806339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check file quantity \nprint('train image quantity:', len(data_img_list))\nprint('cat:', len(img_cat_list))\nprint('dog:', len(img_dog_list))\nprint()\nprint('prediction target test image quantity:', len(test_img_list))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:27:06.881265Z","iopub.execute_input":"2021-05-28T04:27:06.881592Z","iopub.status.idle":"2021-05-28T04:27:06.887178Z","shell.execute_reply.started":"2021-05-28T04:27:06.881562Z","shell.execute_reply":"2021-05-28T04:27:06.886231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check file number\nfor d in dirs:\n    for label in target_labels:\n        print(os.path.join(train_root_path, d, label))\n        print(len([file for file in os.listdir(os.path.join(train_root_path, d, label))]))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:27:10.935662Z","iopub.execute_input":"2021-05-28T04:27:10.936018Z","iopub.status.idle":"2021-05-28T04:27:10.958534Z","shell.execute_reply.started":"2021-05-28T04:27:10.935988Z","shell.execute_reply":"2021-05-28T04:27:10.957223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check file quantity in each directory.Above quantity shows correct copy picture process.","metadata":{}},{"cell_type":"code","source":"!tree -d '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:32:12.54581Z","iopub.execute_input":"2021-05-28T04:32:12.546199Z","iopub.status.idle":"2021-05-28T04:32:13.363865Z","shell.execute_reply.started":"2021-05-28T04:32:12.546164Z","shell.execute_reply":"2021-05-28T04:32:13.36286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Training","metadata":{}},{"cell_type":"markdown","source":"## 3-1. setting for training","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-4\nbatch_size = 20\ninput_height , input_width = 300, 300\nrandom_split = 1\nepochs = 200\n\n# model name setting\nmodel_name_list = ['efficient_net', 'mynet', ]","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:56:47.933753Z","iopub.execute_input":"2021-05-28T00:56:47.934137Z","iopub.status.idle":"2021-05-28T00:56:47.938779Z","shell.execute_reply.started":"2021-05-28T00:56:47.934105Z","shell.execute_reply":"2021-05-28T00:56:47.937857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-2. dataset confirmation","metadata":{}},{"cell_type":"code","source":"# 画像の表示\nim = Image.open(os.path.join(train_raw_path, img_dog_list[0]))\nprint(os.path.join(train_raw_path, img_dog_list[0]))\nplt.imshow(im)\nplt.title(img_dog_list[0])\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:18.147857Z","iopub.execute_input":"2021-05-28T00:57:18.148225Z","iopub.status.idle":"2021-05-28T00:57:18.465824Z","shell.execute_reply.started":"2021-05-28T00:57:18.148195Z","shell.execute_reply":"2021-05-28T00:57:18.464862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['cat', 'dog']\nlabel_description = {\n    '0': 'cat',\n    '1': 'dog',\n}\n\nfor label in labels:\n    f, ax = plt.subplots(figsize=(12,10))\n    if label == 'cat':\n        img_list = img_cat_list\n        \n    elif label == 'dog':\n        img_list = img_dog_list\n        \n    # show pictures 3 x 3 \n    for x in range(9):\n        plt.subplot(3, 3, x+1)\n        im = Image.open(os.path.join(train_raw_path, img_list[x]))\n        plt.axis('off')\n        plt.title(img_list[x])\n        plt.imshow(im)\n        \n    print(f'\\t\\t\\t\\t# {label}')\n    plt.show()\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:31.453906Z","iopub.execute_input":"2021-05-28T00:57:31.454265Z","iopub.status.idle":"2021-05-28T00:57:32.834733Z","shell.execute_reply.started":"2021-05-28T00:57:31.454235Z","shell.execute_reply":"2021-05-28T00:57:32.833771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-3. ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"# All images will be rescaled by 1./255\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(input_height, input_width),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalid_generator = valid_datagen.flow_from_directory(\n        valid_dir,\n        target_size=(input_height, input_width),\n        batch_size=20,\n        class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:42.250796Z","iopub.execute_input":"2021-05-28T00:57:42.251174Z","iopub.status.idle":"2021-05-28T00:57:42.926144Z","shell.execute_reply.started":"2021-05-28T00:57:42.251142Z","shell.execute_reply":"2021-05-28T00:57:42.925166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-4. Network definition","metadata":{}},{"cell_type":"code","source":"def efficientnet_model(input_height, input_width):\n    model = Sequential()\n    model.add( tf.keras.applications.EfficientNetB3(\n    include_top=False,\n    weights=\"imagenet\", input_shape=(input_height, input_width, 3)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:45.608841Z","iopub.execute_input":"2021-05-28T00:57:45.609226Z","iopub.status.idle":"2021-05-28T00:57:45.619558Z","shell.execute_reply.started":"2021-05-28T00:57:45.609192Z","shell.execute_reply":"2021-05-28T00:57:45.6186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mymodel(input_height, input_width):\n    # モデルの作成\n    mymodel = Sequential()\n    mymodel.add(Conv2D(32, kernel_size=3, padding=\"same\", activation='relu', input_shape=(input_height, input_width, 3)))\n    mymodel.add(MaxPooling2D(pool_size=(3, 3)))\n    mymodel.add(Conv2D(64, kernel_size=3, padding=\"same\", activation='relu'))\n    mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n    mymodel.add(Conv2D(128, kernel_size=3, padding=\"same\", activation='relu'))\n    mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n    mymodel.add(Flatten())    #Flatten()により特徴マップをベクトルに変換し、後続の全結合層と繋げられるようにする\n    mymodel.add(Dense(384, activation='relu'))\n    mymodel.add(Dense(128, activation='relu'))\n    mymodel.add(Dense(1, activation='sigmoid'))    #Softmax関数にて、クラス毎の確率として出力\n\n    return mymodel","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:49.638532Z","iopub.execute_input":"2021-05-28T00:57:49.638857Z","iopub.status.idle":"2021-05-28T00:57:49.647804Z","shell.execute_reply.started":"2021-05-28T00:57:49.638827Z","shell.execute_reply":"2021-05-28T00:57:49.646572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding some model network definition","metadata":{}},{"cell_type":"code","source":"'''\ndef mymodel2 (input_height, input_width, num_classes):\n  # network layer\n  # write code and define network\n\n  return model\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:53.544336Z","iopub.execute_input":"2021-05-28T00:57:53.544665Z","iopub.status.idle":"2021-05-28T00:57:53.550349Z","shell.execute_reply.started":"2021-05-28T00:57:53.544632Z","shell.execute_reply":"2021-05-28T00:57:53.549261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_answer(x):\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:56.315421Z","iopub.execute_input":"2021-05-28T00:57:56.315868Z","iopub.status.idle":"2021-05-28T00:57:56.322175Z","shell.execute_reply.started":"2021-05-28T00:57:56.315826Z","shell.execute_reply":"2021-05-28T00:57:56.321326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_selected = get_answer(widgets.RadioButtons(options=model_name_list))\ndisplay(model_selected)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:57:59.242112Z","iopub.execute_input":"2021-05-28T00:57:59.242446Z","iopub.status.idle":"2021-05-28T00:57:59.261641Z","shell.execute_reply.started":"2021-05-28T00:57:59.242417Z","shell.execute_reply":"2021-05-28T00:57:59.260683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = model_selected.value\nprint(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T00:58:02.796319Z","iopub.execute_input":"2021-05-28T00:58:02.796656Z","iopub.status.idle":"2021-05-28T00:58:02.801358Z","shell.execute_reply.started":"2021-05-28T00:58:02.796625Z","shell.execute_reply":"2021-05-28T00:58:02.800389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_model(model_name, input_height, input_width):\n    if model_name == 'mymodel':\n        model = mymodel(input_height, input_width)\n    elif model_name == 'efficient_net':\n        model = efficientnet_model(input_height, input_width)\n\n    return model\n\nmodel = select_model(model_name, input_height, input_width)\n\n# display model summary \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:51:41.43377Z","iopub.execute_input":"2021-05-28T04:51:41.434155Z","iopub.status.idle":"2021-05-28T04:51:44.869887Z","shell.execute_reply.started":"2021-05-28T04:51:41.434122Z","shell.execute_reply":"2021-05-28T04:51:44.868198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-5. train","metadata":{}},{"cell_type":"code","source":"# compile model with some setting item\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=learning_rate),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:51:44.871432Z","iopub.execute_input":"2021-05-28T04:51:44.871794Z","iopub.status.idle":"2021-05-28T04:51:44.890818Z","shell.execute_reply.started":"2021-05-28T04:51:44.871755Z","shell.execute_reply":"2021-05-28T04:51:44.889957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                           patiene = 3,\n                                           verbose = 1,\n                                           factor = 0.5,\n                                           min_lr = 0.00001)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=5)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:51:57.23552Z","iopub.execute_input":"2021-05-28T04:51:57.235855Z","iopub.status.idle":"2021-05-28T04:51:57.240651Z","shell.execute_reply.started":"2021-05-28T04:51:57.235823Z","shell.execute_reply":"2021-05-28T04:51:57.239681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\n      epochs=100,\n      validation_data=valid_generator,\n      validation_steps=50,  # 1000 images = batch_size * steps\n      verbose=2,\n      # callbacks = [learning_rate_reduction, early_stopping],\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:51:58.656687Z","iopub.execute_input":"2021-05-28T04:51:58.657097Z","iopub.status.idle":"2021-05-28T06:21:22.059212Z","shell.execute_reply.started":"2021-05-28T04:51:58.657065Z","shell.execute_reply":"2021-05-28T06:21:22.058309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T07:11:19.231506Z","iopub.execute_input":"2021-05-28T07:11:19.231876Z","iopub.status.idle":"2021-05-28T07:11:19.296153Z","shell.execute_reply.started":"2021-05-28T07:11:19.231792Z","shell.execute_reply":"2021-05-28T07:11:19.294786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"        ","metadata":{}},{"cell_type":"markdown","source":"# 4. Save Model","metadata":{}},{"cell_type":"code","source":"# Save Model\nmodel.save(root_path + '/model.h5' )    # model\nmodel.save_weights(root_path + '/model_weights.h5')    # model parameter","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:20:19.52497Z","iopub.status.idle":"2021-05-28T03:20:19.525355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\n# from keras.models import load_model\n# model = load_model(root_path + '/model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:20:19.528653Z","iopub.status.idle":"2021-05-28T03:20:19.529044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Model evaluation","metadata":{}},{"cell_type":"markdown","source":"## 5-1. Confusion matrix","metadata":{}},{"cell_type":"code","source":"eval_datagen = ImageDataGenerator(rescale=1./255)\neval_generator = eval_datagen.flow_from_directory(\n    train_raw_root_path,\n    target_size=(input_height, input_width),\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)\n\nprint('evaluation(all pictures(raw train dataset) ：', len(data_img_list))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:32:35.498641Z","iopub.execute_input":"2021-05-28T04:32:35.499116Z","iopub.status.idle":"2021-05-28T04:32:36.178375Z","shell.execute_reply.started":"2021-05-28T04:32:35.499071Z","shell.execute_reply":"2021-05-28T04:32:36.176882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_pred_proba = model.predict(\n    eval_generator,\n    steps=len(data_img_list),\n    verbose=0)\n\n# probability value is predicted\nprint(eval_pred_proba.shape)\neval_pred_class = np.where(eval_pred_proba < 0.5, 0, 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:41:18.005874Z","iopub.execute_input":"2021-05-28T04:41:18.006246Z","iopub.status.idle":"2021-05-28T04:47:02.134323Z","shell.execute_reply.started":"2021-05-28T04:41:18.006216Z","shell.execute_reply":"2021-05-28T04:47:02.133399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_class = []\ntrue_class_name = []\nfor f in os.listdir(train_raw_path):\n    class_name = f.split('.')[0]\n    true_class_name.append(class_name)\n    if class_name == 'cat':\n        true_class.append(0)\n    elif class_name == 'dog':\n        true_class.append(1)\n    else:\n        continue\n        \nprint(true_class[0:10])\nprint(true_class_name[0:10])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:50:38.235237Z","iopub.execute_input":"2021-05-28T04:50:38.235621Z","iopub.status.idle":"2021-05-28T04:50:38.271167Z","shell.execute_reply.started":"2021-05-28T04:50:38.235589Z","shell.execute_reply":"2021-05-28T04:50:38.270104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\neval_cmx = confusion_matrix(true_class, eval_pred_class)\n\n# DataFrame\neval_cmx_df = pd.DataFrame(eval_cmx, columns=target_labels, index=target_labels)\n\nprint('Confution matrix with train all pics data')\n\n# 結果の表示\neval_cmx_df","metadata":{"execution":{"iopub.status.busy":"2021-05-28T04:50:53.275427Z","iopub.execute_input":"2021-05-28T04:50:53.275831Z","iopub.status.idle":"2021-05-28T04:50:53.361611Z","shell.execute_reply.started":"2021-05-28T04:50:53.275796Z","shell.execute_reply":"2021-05-28T04:50:53.360812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nprint('accuracy:', accuracy_score(true_class, eval_pred_class))\nprint('precision:', precision_score(true_class, eval_pred_class, average='macro'))\nprint('recall:', recall_score(true_class, eval_pred_class, average='macro'))\nprint('f1:', f1_score(true_class, eval_pred_class, average='macro'))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:20:19.539175Z","iopub.status.idle":"2021-05-28T03:20:19.539859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.heatmap(eval_cmx, annot=True, cmap='Blues')\nplt.savefig(root_path + '/' + 'sklearn_confusion_matrix.png')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:20:19.540903Z","iopub.status.idle":"2021-05-28T03:20:19.541608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Prediction with Test data","metadata":{}},{"cell_type":"code","source":"# Again, test path folder shall have one more folder at least and test data shall be stored in the folder\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(input_height, input_width),\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)\n\nprint('test data quantity：', len(test_img_list))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:38:21.266328Z","iopub.execute_input":"2021-05-28T02:38:21.266657Z","iopub.status.idle":"2021-05-28T02:38:21.607175Z","shell.execute_reply.started":"2021-05-28T02:38:21.266628Z","shell.execute_reply":"2021-05-28T02:38:21.606349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_proba = model.predict(\n    test_generator,\n    steps=len(test_img_list),\n    verbose=0)\n\nprint(test_pred_proba.shape)\ntest_pred_class = np.where(test_pred_proba < 0.5, 0, 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:38:23.141689Z","iopub.execute_input":"2021-05-28T02:38:23.142118Z","iopub.status.idle":"2021-05-28T02:40:57.477638Z","shell.execute_reply.started":"2021-05-28T02:38:23.142085Z","shell.execute_reply":"2021-05-28T02:40:57.476039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Create Submission file","metadata":{}},{"cell_type":"code","source":"test_filename_list=[]\nfor f in test_img_list:\n    test_filename_list.append(f.split('.')[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T02:53:41.409033Z","iopub.execute_input":"2021-05-28T02:53:41.409362Z","iopub.status.idle":"2021-05-28T02:53:41.418248Z","shell.execute_reply.started":"2021-05-28T02:53:41.409332Z","shell.execute_reply":"2021-05-28T02:53:41.417164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_id = pd.DataFrame(test_filename_list, columns=['id'])\nresult_label = pd.DataFrame(test_pred_class, columns=['label'])\nresult_for_submit = pd.concat([result_id, result_label], axis=1)\nresult_for_submit.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:09:24.481874Z","iopub.execute_input":"2021-05-28T03:09:24.48224Z","iopub.status.idle":"2021-05-28T03:09:24.494219Z","shell.execute_reply.started":"2021-05-28T03:09:24.482211Z","shell.execute_reply":"2021-05-28T03:09:24.493417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_for_submit.to_csv(submit_file, sep=\",\", header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T03:09:58.750638Z","iopub.execute_input":"2021-05-28T03:09:58.750973Z","iopub.status.idle":"2021-05-28T03:09:58.779992Z","shell.execute_reply.started":"2021-05-28T03:09:58.750939Z","shell.execute_reply":"2021-05-28T03:09:58.779227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------unimplimented-------------------------------","metadata":{}},{"cell_type":"code","source":"'''\n# ファイル名に付ける日時データの文字列作成\nimport datetime\n\ndt_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\nd_today = datetime.date.today()\n\nfiletime = str(d_today)+'_'+str(dt_now.hour)+str(dt_now.minute)\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nhist  = model.fit(\n    train_generator,\n    validation_data = valid_generator,\n    steps_per_epoch = len(df_train)*0.9//batch_size,\n    validation_steps = len(df_train)*0.1//batch_size, \n    epochs = epochs,\n    # callbacks = [model_checkpoint, early_stopping])\n    callbacks = [model_checkpoint, learning_rate_reduction, early_stopping])\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# cp_cb = ModelCheckpoint(model_path + '/checkpoint/' + \"{epoch}\"+\"checkpoint.h5\", verbose=1, save_best_only=True)\nmodel_checkpoint = ModelCheckpoint(\n        filepath = f'{root_path}/checkpoint.h5',\n        save_weights_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True)\n'''","metadata":{},"execution_count":null,"outputs":[]}]}